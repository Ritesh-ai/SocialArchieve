#!C:\Users\Ritesh\PycharmProjects\MyPro\venv\Scripts\python.exeimport requestsimport jsonimport pandas as pdimport sysimport urllib as requestimport loggingimport cgiimport datetimeimport timeimport openpyxlimport urllib# import urllib.request.urlretrieveimport webbrowser as wb##### ---- Twitter Imports----------------------------------------------------------------------------------------from tweepy import APIfrom tweepy import Cursorfrom tweepy.streaming import StreamListenerfrom tweepy.streaming import StreamListenerfrom tweepy import OAuthHandlerfrom tweepy import Streamimport tweepyimport sysimport pandas as pdimport webbrowser as wbimport tweepyfrom tweepy import APIfrom tweepy import Cursor####---------------------------------------------------------------------------------------------------------------file_path = "C:\\Users\\Ritesh\\Downloads\\"#------------------------------------------Logging For Debugging---------------------------------------------------log_lvl_val = 20logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',level=log_lvl_val)log = logging.getLogger(__file__)log.info("Hey its start")#------------------------------------------------------------------------------------------------------------------def fb_token(Access_Token):    try:        try:            time.sleep(2)            f = open('C:\\Users\\Ritesh\\Downloads\\zanjo', 'r')            data = f.read()        except:            try:                time.sleep(2)                f = open('C:\\Users\\Ritesh\\Downloads\\zanjo', 'r')                data = f.read()            except:                pass        # print(data)        df = pd.read_json(data).fillna('')        created_time, story, id, message = [], [], [], []        for item in df['feed'].tolist():            if item != 'nan':                try:                    for feed in item:                        if feed != 'cursors':                            # print(feed)                            created_time.append(feed['created_time'].replace('T', ' ').split('+')[0])                            id.append(feed['id'])                            try:                                story.append(feed['story'])                            except:                                story.append('')                            try:                                message.append(feed['message'])                            except:                                message.append('')                except:                    pass            else:                continue        album_created_time, name, album_id = [], [], []        for item in df['albums'].tolist():            if item != 'nan':                try:                    for feed in item:                        if feed != 'cursors':                            album_created_time.append(feed['created_time'].replace('T', ' ').split('+')[0])                            name.append(feed['name'])                            album_id.append(feed['id'])                except:                    pass            else:                continue        album_df = pd.DataFrame({'album_id': album_id, 'album_created_time': album_created_time, 'album_name': name})        feed_df = pd.DataFrame({'post_id': id, 'post_created_time': created_time, 'post_story': story, 'post_message': message})        writer = pd.ExcelWriter('C:\\Users\\Ritesh\\Downloads\\facebook_'+str(datetime.datetime.now().date())+'xlsx')        album_df = pd.DataFrame({'album_id': album_id, 'album_created_time': album_created_time, 'album_name': name})        album_df.to_excel(writer, 'Album')        feed_df = pd.DataFrame({'post_id': id, 'post_created_time': created_time, 'post_story': story, 'post_message': message})        feed_df.to_excel(writer, 'Feeds')        writer.save()        return 1    except:        return 0def permit():    consumer_key = '4Ap2KroBqGgT9SYyFxRSyorF0'    consumer_secret = 'sn1C7LAxdfPRsURqSfj8vUqln44CSDYDmTVDgZGcuJUqWvOZa8'    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)    auth.get_authorization_url()    return authdef twitter(pin,auth):    try:        # auth = permit()        # pin = input('Verification Oauth number from Redirect Url: ').strip()        # print(type(pin))        # pin = str(pin_code).strip()        token = auth.get_access_token(verifier=pin)        auth.set_access_token(token[0], token[1])        twitter_client = API(auth)        twitter_data = pd.DataFrame([{'id': data.id_str, 'created_at': data.created_at, 'name': data.user.name, 'location': data.user.location,                 'text': data.text.encode("utf-8"), 'retweet_count': data.retweet_count,                 'favorite_count': data.favorite_count, 'followers_count': data.user.followers_count,                 'status_count': data.user.statuses_count,                 'profile_background_image': data.user.profile_background_image_url_https,                 'profile_image_url_https': data.user.profile_image_url_https} for data in                Cursor(twitter_client.user_timeline).items()])        images_url = []        for item in Cursor(twitter_client.user_timeline).items():            try:                images_url.append(list(list(item.entities.values())[-1][0].values())[4])            except:                images_url.append('')        twitter_data['images_url'] = images_url        try:            for index, item in enumerate(images_url):                urllib.request.urlretrieve(str(item), file_path + 'twitter\\twitter_images\\' + str(index) + '.jpg')        except Exception as e:            pass        twitter_data.to_excel(file_path+'twitter\\twitter_data__'+str(datetime.datetime.now().date())+'.xlsx')        return 1    except Exception as e:        return 0# a = twitter('NZxUD9QzOD4ZVwWhpqrolgAM6Ew9xQpJ')# print(a)def Insta(APP_ACCESS_TOKEN):    BASE_URL = 'https://api.instagram.com/v1/'    # APP_ACCESS_TOKEN = '8231587445.4c9486f.6f6278ec003c4e7ab362482ff1615fbc'    log.info("In the Insta..")    request_url = (BASE_URL + 'users/self/media/recent/?access_token=%s') % (APP_ACCESS_TOKEN)    recent_post = requests.get(request_url).json()['data']    result_data = pd.io.json.json_normalize(recent_post)    # result_data.to_excel('Data.xlsx')    # print(result_data['caption'].to_frame().all().isnull().tolist()[0])    # sys.exit()    try:        try:            if result_data['caption'].to_frame().all().isnull().tolist()[0] == True:                # result_data['caption_create_time'] = result_data['caption.created_time']                mask = ['attribution','caption', 'caption.from.id', 'caption.created_time', 'caption.from.username', 'caption.id', 'id',                        'created_time', 'images.low_resolution.url', 'comments.count', 'filter', 'images.low_resolution.height',                        'images.low_resolution.width', 'images.standard_resolution.height', 'images.standard_resolution.width',                        'images.thumbnail.height', 'images.thumbnail.width', 'location', 'tags', 'type', 'user.id', 'user.username',                        'user_has_liked', 'users_in_photo']                result = result_data.drop(mask, axis=1)                result.rename(columns={'caption.from.full_name': 'caption_name', 'caption.from.profile_picture': 'caption_picture',                                       'caption.text': 'caption_text', 'images.standard_resolution.url': 'images_url',                                       'images.thumbnail.url': 'thumbnail_url', 'likes.count': 'likesCount',                                       'user.full_name': 'username', 'user.profile_picture': 'profile_picture'}, inplace=True)                try:                    for index, item in enumerate(result['images_url'].tolist()):                        urllib.request.urlretrieve(str(item), file_path + 'instagram\\Insta_images\\' + str(index) + '.jpg')                except Exception as e:                    print(e)                result.to_excel(file_path+'instagram\\Insta__' + str(datetime.datetime.now().date()) + '.xlsx')                return 1            else:                try:                    mask = ['attribution', 'caption', 'id', 'images.low_resolution.url', 'comments.count', 'filter',                            'images.low_resolution.height', 'images.low_resolution.width', 'images.standard_resolution.height',                            'images.standard_resolution.width', 'images.thumbnail.height', 'images.thumbnail.width', 'location',                            'tags', 'type', 'user.id', 'user.username', 'user_has_liked', 'users_in_photo']                    result = result_data.drop(mask, axis=1)                    result.rename(columns={'images.standard_resolution.url': 'images_url', 'images.thumbnail.url': 'thumbnail_url','likes.count': 'likesCount', 'user.full_name': 'username','user.profile_picture': 'profile_picture'}, inplace=True)                    try:                        for index, item in enumerate(result['images_url'].tolist()):                            urllib.request.urlretrieve(str(item), file_path + 'instagram\\Insta_images\\' + str(index) + '.jpg')                    except Exception as e:                        print(e)                    result.to_excel(file_path+'instagram\\Insta__' + str(datetime.datetime.now().date()) + '.xlsx')                    return 1                except:                    mask = ['attribution', 'caption', 'comments.count', 'filter', 'id', 'images.low_resolution.height',                            'images.low_resolution.url', 'images.low_resolution.width', 'images.standard_resolution.height',                            'images.standard_resolution.width', 'images.thumbnail.height', 'images.thumbnail.width',                            'location.id',                            'location.latitude', 'location.longitude', 'tags', 'type', 'user.id', 'user.username',                            'user_has_liked', 'users_in_photo']                    result = result_data.drop(mask, axis=1)                    result.rename(columns=                                  {'location.name': 'location_name', 'user.full_name': 'username',                                   'user.profile_picture': 'profile_picture',                                   'likes.count': 'likesCount', 'images.standard_resolution.url': 'images_url',                                   'images.thumbnail.url': 'thumbnail_url', }, inplace=True)                    result['images_url'].apply(lambda x: urllib.request.urlretrieve(str(x), '1.jpg'))                    try:                        for index, item in enumerate(result['images_url'].tolist()):                            urllib.request.urlretrieve(str(item), file_path + 'instagram\\Insta_images\\' + str(index) + '.jpg')                    except Exception as e:                        print(e)                    result.to_excel(file_path + 'instagram\\Insta__' + str(datetime.datetime.now().date()) + '.xlsx')                    return 1        except:            result_data['caption_create_time'] = result_data['caption.created_time']            mask = ['attribution', 'caption.from.id', 'caption.created_time', 'caption.from.username',                    'caption.id', 'id',                    'created_time', 'images.low_resolution.url', 'comments.count', 'filter', 'images.low_resolution.height',                    'images.low_resolution.width', 'images.standard_resolution.height', 'images.standard_resolution.width',                    'images.thumbnail.height', 'images.thumbnail.width', 'location', 'tags', 'type', 'user.id',                    'user.username',                    'user_has_liked', 'users_in_photo']            result = result_data.drop(mask, axis=1)            result.rename(                columns={'caption.from.full_name': 'caption_name', 'caption.from.profile_picture': 'caption_picture',                         'caption.text': 'caption_text', 'images.standard_resolution.url': 'images_url',                         'images.thumbnail.url': 'thumbnail_url', 'likes.count': 'likesCount',                         'user.full_name': 'username', 'user.profile_picture': 'profile_picture'}, inplace=True)            # result['images_url'].apply(lambda x: urllib.request.urlretrieve(str(x),'1.jpg'))            try:                for index,item in enumerate(result['images_url'].tolist()):                    urllib.request.urlretrieve(str(item),file_path+'instagram\\Insta_images\\'+str(index)+'.jpg')            except Exception as e:                print(e)            result.to_excel(file_path+'instagram\\Insta__' + str(datetime.datetime.now().date()) + '.xlsx')            return 1    except:        return 0def google_plus(google_data):    try:        data = [{"id": data['actor']['id'], 'text': data['title'], 'Date': data['published'],                 "UserName": data['actor']['displayName'], "post_url": data['object']['url']} for data in                list(google_data.values())[-1]]        google_plus_data = pd.DataFrame(data)        images_url, image_link = [], []        for data in list(activities_document.values())[-1]:            try:                images_url.append(data['object']['attachments'][0]['url'])                image_link.append(data['object']['attachments'][0]['image']['url'])            except:                images_url.append('')                image_link.append('')        google_plus_data['images_url'] = images_url        google_plus_data['image_link'] = image_link        try:            for index, item in enumerate(image_link):                urllib.request.urlretrieve(str(item),'C:\\Users\\Ritesh\\Downloads\\google_plus\\google_plus_images\\' + str(index) + '.jpg')        except Exception as e:            pass        google_plus_data.to_excel('C:\\Users\\Ritesh\\Downloads\\google_plus\\google_plus__'+str(datetime.datetime.now().date())+'xlsx')        return 1    except:        return 0